

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Posts by Collection - Siteng Huang</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Siteng Huang">
<meta property="og:title" content="Posts by Collection">


  <link rel="canonical" href="http://localhost:4000/collection-archive/">
  <meta property="og:url" content="http://localhost:4000/collection-archive/">







  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Siteng Huang",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Siteng Huang Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Siteng Huang</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#news">News</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#publications">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#experience">Experience</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#services">Services</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#misc">Misc</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.png" class="author__avatar" alt="Siteng Huang">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Siteng Huang</h3>
    <p class="author__bio">Ph.D. Student @ Zhejiang University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Hangzhou, China</li>
      
      
      
      
        <li><a href="mailto:siteng.huang@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
        <li><a href="https://twitter.com/KyonHuang"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/bighuang624"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=mhpkWSYAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
        <li><a href="https://orcid.org/0000-0002-9735-1186"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 class="page__title">Posts by Collection</h1>
    
    



  
    
    
      <h2 id="portfolio" class="archive__subtitle">portfolio</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/portfolio/portfolio-1/" rel="permalink">Portfolio item number 1
</a>
      
    </h2>
    
    

        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Short description of portfolio item number 1<br /><img src="/images/500x300.png" /></p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/portfolio/portfolio-2/" rel="permalink">Portfolio item number 2
</a>
      
    </h2>
    
    

        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Short description of portfolio item number 2 <br /><img src="/images/500x300.png" /></p>
</p>
    
    
    

  </article>
</div>

    
  

  
  
    
  
    
  
    
  
    
  
    
  

  
    
    
      <h2 id="publications" class="archive__subtitle">publications</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/dual-self-attention-network" rel="permalink">DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting
</a>
      
    </h2>
    
    

        
          <!-- <p>Published in <i>Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM 2019)</i>, 2019 </p> -->
          <p>Published in <i>Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM 2019)</i></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p><img src="https://kyonhuang.top/files/DSANet/DSANet-model-structure.png" alt="" /> In this paper, we propose a <strong>dual self-attention network (DSANet)</strong> for multivariate time series forecasting, <strong>especially for dynamic-period or nonperiodic series</strong>. DSANet completely dispenses with recurrence and utilizes two parallel convolutional components, called global temporal convolution and local temporal convolution, to capture complex mixtures of global and local temporal patterns. Moreover, DSANet employs a self-attention module to model dependencies between multiple series. To further improve the robustness, DSANet also integrates a traditional autoregressive linear model in parallel to the non-linear neural network. Experiments on real-world multivariate time series data show that the proposed model is effective and outperforms baselines.</p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/attributes-guided-attention-module" rel="permalink">Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition
</a>
      
    </h2>
    
    

        
          <!-- <p>Published in <i>Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI 2021)</i>, 2021 </p> -->
          <p>Published in <i>Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI 2021)</i></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><div align="middle"><img align="middle" style="max-width: 540px; width: 100%" src="https://kyonhuang.top/files/AGAM/AGAM-intuition.png" /></div>
<p>In this paper, we devise an <strong>attributes-guided attention module (AGAM)</strong> to utilize human-annotated attributes and learn more discriminative features for few-shot recognition. This plug-and-play module enables visual contents and corresponding attributes to collectively focus on important channels and regions for the support set. And the feature selection is also achieved for query set with only visual information while the attributes are not available. Therefore, representations from both sets are improved in a fine-grained manner. Moreover, an <strong>attention alignment mechanism</strong> is proposed to distill knowledge from the guidance of attributes to the pure-visual branch for samples without attributes. Extensive experiments and analysis show that our proposed module can significantly improve simple metric-based approaches to achieve state-of-the-art performance on different datasets and settings.</p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/reference-limited-CZSL" rel="permalink">Reference-Limited Compositional Zero-Shot Learning
</a>
      
    </h2>
    
    

        
          <!-- <p>Published in <i>Proceedings of the 2023 ACM International Conference on Multimedia Retrieval (ICMR 2023)</i>, 2023 </p> -->
          <p>Published in <i>Proceedings of the 2023 ACM International Conference on Multimedia Retrieval (ICMR 2023)</i></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><div align="middle"><img align="middle" style="max-width: 520px; width: 100%" src="https://kyonhuang.top/files/RLCZSL/RLCZSL-setting-comparison.png" /></div>
<p>While considerable progress has been made on existing benchmarks, we suspect whether popular compositional zero-shot learning (CZSL) methods can address the challenges of few-shot and few referential compositions, which is common when learning in real-world unseen environments. To this end, we study the challenging <strong>reference-limited compositional zero-shot learning (RL-CZSL)</strong> problem in this paper, <em>i.e.</em>, given limited seen compositions that contain only a few samples as reference, unseen compositions of observed primitives should be identified. We propose a novel <strong>Meta Compositional Graph Learner (MetaCGL)</strong> that can efficiently learn the compositionality from insufficient referential information and generalize to unseen compositions. Besides, we build <strong>a benchmark with two new large-scale datasets</strong> that consist of natural images with diverse compositional labels, providing more realistic environments for RL-CZSL. Extensive experiments in the benchmarks show that our method achieves state-of-the-art performance in recognizing unseen compositions when reference is limited for compositional learning.</p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/Troika" rel="permalink">Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning
</a>
      
    </h2>
    
    

        
          <!-- <p>Published in <i>arXiv preprint arXiv:2303.15230</i>, 2023 </p> -->
          <p>Published in <i>arXiv preprint arXiv:2303.15230</i></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><div align="middle"><img align="middle" style="max-width: 520px; width: 100%" src="https://kyonhuang.top/files/Troika/Troika-paradigm-comparison.png" /></div>
<p>With a particular focus on the universality of the solution, in this work, we propose a novel <strong>Multi-Path paradigm</strong> for VLM-based CZSL models that establishes three identification branches to jointly model the state, object, and composition. The presented <strong>Troika</strong> is an outstanding implementation that aligns the branch-specific prompt representations with decomposed visual features. To calibrate the bias between semantically similar multi-modal representations, we further devise a <strong>Cross-Modal Traction module</strong> into Troika that shifts the prompt representation towards the current visual content. Experiments show that on the closed-world setting, Troika exceeds the current state-of-the-art methods by up to <strong>+7.4%</strong> HM and <strong>+5.7%</strong> AUC. And on the more challenging open-world setting, Troika still surpasses the best CLIP-based method by up to <strong>+3.8%</strong> HM and <strong>+2.7%</strong> AUC.</p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/text-video-cooperative-prompt-tuning" rel="permalink">VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval
</a>
      
    </h2>
    
    

        
          <!-- <p>Published in <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023 (CVPR 2023)</i>, 2023 </p> -->
          <p>Published in <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023 (CVPR 2023)</i></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><div align="middle"><img align="middle" style="max-width: 560px; width: 100%" src="https://kyonhuang.top/files/VoP/VoP-comparison.png" /></div>
<p>In this work, we propose the <strong>VoP</strong>: Text-<strong>V</strong>ideo C<strong>o</strong>-operative <strong>P</strong>rompt Tuning for efficient tuning on the text-video retrieval task. The proposed VoP is an end-to-end framework with both video &amp; text prompts introducing, which can be regarded as a powerful baseline with only <strong>0.1%</strong> trainable parameters. Further, based on the spatio-temporal characteristics of videos, we develop three novel video prompt mechanisms to improve the performance with different scales of trainable parameters. The basic idea of the VoP enhancement is to model the frame position, frame context, and layer function with specific trainable prompts, respectively. Extensive experiments show that compared to full finetuning, the enhanced VoP achieves a <strong>1.4%</strong> average R@1 gain across five text-video retrieval benchmarks with <strong>6Ã—</strong> less parameter overhead.</p>
</p>
    
    
    

  </article>
</div>

    
  

  
    
    
      <h2 id="talks" class="archive__subtitle">talks</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2012-03-01-talk-1" rel="permalink">Talk 1 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2012-03-01T00:00:00-08:00">March 01, 2012</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of your talk, which is a markdown files that can be all markdown-ified like any other post. Yay markdown!</p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2013-03-01-tutorial-1" rel="permalink">Tutorial 1 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2013-03-01T00:00:00-08:00">March 01, 2013</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p><a href="http://exampleurl.com">More information here</a></p>

</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2014-02-01-talk-2" rel="permalink">Talk 2 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2014-02-01T00:00:00-08:00">February 01, 2014</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p><a href="http://example2.com">More information here</a></p>

</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2014-03-01-talk-3" rel="permalink">Conference Proceeding talk 3 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2014-03-01T00:00:00-08:00">March 01, 2014</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of your conference proceedings talk, note the different field in type. You can put anything in this field.</p>
</p>
    
    
    

  </article>
</div>

    
  

  
    
    
      <h2 id="teaching" class="archive__subtitle">teaching</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/teaching/2014-spring-teaching-1" rel="permalink">Teaching experience 1
</a>
      
    </h2>
    
    

        
          <p> Undergraduate course, <i>University 1, Department</i>, 2014 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of a teaching experience. You can use markdown like any other post.</p>

</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/teaching/2015-spring-teaching-1" rel="permalink">Teaching experience 2
</a>
      
    </h2>
    
    

        
          <p> Workshop, <i>University 1, Department</i>, 2015 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of a teaching experience. You can use markdown like any other post.</p>

</p>
    
    
    

  </article>
</div>

    
  

  </div>
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- moved to footer.html -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<a href="/sitemap/">Sitemap</a>&nbsp;&nbsp;|&nbsp;&nbsp;<span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span> views.</span>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/bighuang624"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>



<div class="page__footer-copyright">&copy; 2023 Siteng Huang. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

