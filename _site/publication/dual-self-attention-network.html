

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting - Yalun Wu</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Yalun Wu">
<meta property="og:title" content="DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting">


  <link rel="canonical" href="http://localhost:4000/publication/dual-self-attention-network">
  <meta property="og:url" content="http://localhost:4000/publication/dual-self-attention-network">



  <meta property="og:description" content=" In this paper, we propose a dual self-attention network (DSANet) for multivariate time series forecasting, especially for dynamic-period or nonperiodic series. DSANet completely dispenses with recurrence and utilizes two parallel convolutional components, called global temporal convolution and local temporal convolution, to capture complex mixtures of global and local temporal patterns. Moreover, DSANet employs a self-attention module to model dependencies between multiple series. To further improve the robustness, DSANet also integrates a traditional autoregressive linear model in parallel to the non-linear neural network. Experiments on real-world multivariate time series data show that the proposed model is effective and outperforms baselines.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2019-11-03T00:00:00-07:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Yalun Wu",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Yalun Wu Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Yalun Wu</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#news">News</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#publications">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#experience">Experience</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#services">Services</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000\#misc">Misc</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.jpg" class="author__avatar" alt="Yalun Wu">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Yalun Wu</h3>
    <p class="author__bio">Ph.D. Student @ Beijing Jiaotong University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Beijing, China</li>
      
      
      
      
        <li><a href="mailto:wuyalun1@bjtu.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/Allenpandas"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=mhpkWSYAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting">
    <meta itemprop="description" content=" In this paper, we propose a dual self-attention network (DSANet) for multivariate time series forecasting, especially for dynamic-period or nonperiodic series. DSANet completely dispenses with recurrence and utilizes two parallel convolutional components, called global temporal convolution and local temporal convolution, to capture complex mixtures of global and local temporal patterns. Moreover, DSANet employs a self-attention module to model dependencies between multiple series. To further improve the robustness, DSANet also integrates a traditional autoregressive linear model in parallel to the non-linear neural network. Experiments on real-world multivariate time series data show that the proposed model is effective and outperforms baselines.">
    <meta itemprop="datePublished" content="November 03, 2019">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting
</h1>
          
        
        
        
          <!-- <p>Published in <i>Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM 2019)</i>, 2019 </p> -->
          <p>Published in <i>Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM 2019)</i></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p><a href="https://kyonhuang.top/files/DSANet/Huang-DSANet.pdf" class="btn btn--info">paper</a> 
<a href="https://github.com/bighuang624/DSANet" class="btn btn--info">code</a>
<a href="https://kyonhuang.top/files/DSANet/cikm19-DSANet-poster.pdf" class="btn btn--info">poster</a>
<a href="https://kyonhuang.top/files/DSANet/cikm19-DSANet-presentation.pdf" class="btn btn--info">slide</a></p>

<h2 id="background">Background</h2>

<p>Multivariate time series forecasting has attracted wide attention in areas, such as system, traffic, and finance. The difficulty of the task lies in that traditional methods fail to capture complicated non-linear dependencies between time steps and between multiple time series. Recently, recurrent neural network and attention mechanism have been used to model periodic temporal patterns across multiple time steps. However, these models fit not well for time series with dynamic-period patterns or nonperiodic patterns. In this paper, we propose a <strong>dual self-attention network (DSANet)</strong> for highly efficient multivariate time series forecasting, <strong>especially for dynamic-period or nonperiodic series</strong>. Experiments on real-world multivariate time series data show that the proposed model is effective and outperforms baselines.</p>

<h2 id="model-overview">Model Overview</h2>

<p><img src="https://kyonhuang.top/files/DSANet/DSANet-model-structure.png" alt="" /></p>

<ul>
  <li><strong>Global Temporal Convolution</strong>: First, DSANet applies 1D convolution over all time steps to extract global temporal patterns for univariate time series.</li>
  <li><strong>Local Temporal Convolution</strong>: Considering that time steps with a shorter relative distance have a larger impact on each other, DSANet uses another 1D convolution with shorter length of filters to model local temporal patterns.</li>
  <li><strong>Self-attention Module</strong>: To capture the dependencies between different series, a self-attention module inspired by the Transformer (<a href="https://arxiv.org/abs/1706.03762">Vaswani et al., 2017</a>) is applied.</li>
  <li><strong>Autoregressive Component</strong>: To address the drawback that the scale of neural network output is not sensitive to that of input, the final prediction of DSANet is a mixture of the non-linear component and a classical autoregressive model.</li>
</ul>

<h2 id="experiment-results">Experiment Results</h2>

<p>We conduct our experiments on a large multivariate time series dataset, which contains the daily revenue of geographically close gas stations. Data visualization analysis is performed to ensure that the data set does not contain distinct repetitive patterns. Please check the paper for the details of the experiment settings and further analysis.</p>

<h3 id="evaluation-results">Evaluation Results</h3>

<p>Each row in the table compares the results of all methods in a particular metric with a specific window-horizon pair, and each column shows the results of a specific method in all cases. Boldface indicates the best result of each row in a particular metric.</p>

<p>With <em>window</em> = 32:</p>

<p><img src="https://kyonhuang.top/files/DSANet/exp_results_window_32.png" alt="" /></p>

<p>With <em>window</em> = 64:</p>

<p><img src="https://kyonhuang.top/files/DSANet/exp_results_window_64.png" alt="" /></p>

<p>With <em>window</em> = 128:</p>

<p><img src="https://kyonhuang.top/files/DSANet/exp_results_window_128.png" alt="" /></p>

<h3 id="ablation-study">Ablation Study</h3>

<p>To justify the efficiency of our architecture design, we conduct a careful ablation study. Specifically, we remove each of the components one at a time in our DSANet model:</p>

<ul>
  <li><strong>DSAwoGlobal</strong>: Remove the global temporal convolution branch.</li>
  <li><strong>DSAwoLocal</strong>: Remove the local temporal convolution branch.</li>
  <li><strong>DSAwoAR</strong>: Remove the autoregressive component.</li>
</ul>

<p>With <em>window</em> = 32:</p>

<p><img src="https://kyonhuang.top/files/DSANet/ablation_RRSE.png" alt="" /></p>

<p><img src="https://kyonhuang.top/files/DSANet/ablation_MAE.png" alt="" /></p>

<p><img src="https://kyonhuang.top/files/DSANet/ablation_CORR.png" alt="" /></p>

<p><strong>Observations</strong>:</p>

<ol>
  <li>The best result on each window-horizon pair is obtained by complete DSANet, showing all components have contributed to the effectiveness and robustness of the whole model.</li>
  <li>The performance of DSAwoAR significantly drops, showing that the AR component plays a crucial role. The reason is that AR is generally robust to the scale changing in data according to <a href="https://dl.acm.org/citation.cfm?id=3210006">Lai et al. (2018)</a>.</li>
  <li>DSAwoGlobal and DSAwoLocal also suffer from performance loss but less than removing the AR component. This is because features learned by the two branches coincide. In other words, when one branch is removed, some of the lost features can be obtained from the other branch.</li>
</ol>

<h2 id="related-work">Related Work</h2>

<p>We first consider statistical linear methods for multivariate time series. Here, the vector autoregression (VAR) model is widely considered as a baseline method, which generalizes the univariate autoregressive (AR) model by allowing for more than one evolving variable. To model non-linear relationships, some variants of the autoregressive model are used, such as LRidge, LSVR and Gaussian process (GP). However, they assume certain distribution or function form of time series and fail to capture different forms of nonlinearity.</p>

<p>Due to the ability to flexibly model various non-linear relationships, neural networks are often applied to enable non-linear forecasting models. For example, recurrent neural network models using LSTM or GRU are often used to provide non-linear time series forecasting. To predict more accurately, complex structures such as recurrent-skip layer (LSTNet-S), temporal attention layer (LSTNet-A) (<a href="https://dl.acm.org/citation.cfm?id=3210006">Lai et al., 2018</a>), and a novel temporal pattern attention mechanism (TPA) (<a href="https://link.springer.com/article/10.1007%2Fs10994-019-05815-0">Shih et al., 2018</a>) have been proposed. However, when working on data with dynamic-period patterns or nonperiodic patterns, their performance drops significantly.</p>

<h2 id="bibtex">BibTex</h2>

<p>If our paper and codes are helpful for you research, please cite our paper:</p>

<pre>
@inproceedings{Huang2019DSANet,
  author = {Siteng Huang and Donglin Wang and Xuehan Wu and Ao Tang},
  title = {DSANet: Dual Self-Attention Network for Multivariate Time Series Forecasting},
  booktitle = {Proceedings of the 28th {ACM} International Conference on Information and Knowledge Management},
  month = {November},
  year = {2019},
  address = {Beijing, China}
}
</pre>

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/publication/dual-self-attention-network" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/publication/dual-self-attention-network" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/publication/dual-self-attention-network" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">Previous</a>
    
    
      <a href="http://localhost:4000/publication/attributes-guided-attention-module" class="pagination--pager" title="Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- moved to footer.html -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<a href="/sitemap/">Sitemap</a>&nbsp;&nbsp;|&nbsp;&nbsp;<span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span> views.</span>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/Allenpandas"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>



<div class="page__footer-copyright">&copy; 2023 Yalun Wu. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

